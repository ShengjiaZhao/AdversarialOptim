{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical VAE with Gumbel-Softmax\n",
    "\n",
    "Partial implementation of the paper [Categorical Reparameterization with Gumbel-Softmax](https://arxiv.org/abs/1611.01144) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A categorical VAE with discrete latent variables. Tensorflow version is 0.10.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "slim=tf.contrib.slim\n",
    "Bernoulli = tf.contrib.distributions.Bernoulli\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_gumbel(shape, eps=1e-20): \n",
    "  \"\"\"Sample from Gumbel(0, 1)\"\"\"\n",
    "  U = tf.random_uniform(shape,minval=0,maxval=1)\n",
    "  return -tf.log(-tf.log(U + eps) + eps)\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature): \n",
    "  \"\"\" Draw a sample from the Gumbel-Softmax distribution\"\"\"\n",
    "  y = logits + sample_gumbel(tf.shape(logits))\n",
    "  return tf.nn.softmax( y / temperature)\n",
    "\n",
    "def gumbel_softmax(logits, temperature, hard=False):\n",
    "  \"\"\"Sample from the Gumbel-Softmax distribution and optionally discretize.\n",
    "  Args:\n",
    "    logits: [batch_size, n_class] unnormalized log-probs\n",
    "    temperature: non-negative scalar\n",
    "    hard: if True, take argmax, but differentiate w.r.t. soft sample y\n",
    "  Returns:\n",
    "    [batch_size, n_class] sample from the Gumbel-Softmax distribution.\n",
    "    If hard=True, then the returned sample will be one-hot, otherwise it will\n",
    "    be a probabilitiy distribution that sums to 1 across classes\n",
    "  \"\"\"\n",
    "  y = gumbel_softmax_sample(logits, temperature)\n",
    "  if hard:\n",
    "    k = tf.shape(logits)[-1]\n",
    "    #y_hard = tf.cast(tf.one_hot(tf.argmax(y,1),k), y.dtype)\n",
    "    y_hard = tf.cast(tf.equal(y,tf.reduce_max(y,1,keep_dims=True)),y.dtype)\n",
    "    y = tf.stop_gradient(y_hard - y) + y\n",
    "  return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K=10 # number of classes\n",
    "N=30 # number of categorical distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-0ebec899cf1a>:26: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# input image x (shape=(batch_size,784))\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "# variational posterior q(y|x), i.e. the encoder (shape=(batch_size,200))\n",
    "net = slim.stack(x,slim.fully_connected,[512,256])\n",
    "# unnormalized logits for N separate K-categorical distributions (shape=(batch_size*N,K))\n",
    "logits_y = tf.reshape(slim.fully_connected(net,K*N,activation_fn=None),[-1,K])\n",
    "q_y = tf.nn.softmax(logits_y)\n",
    "log_q_y = tf.log(q_y+1e-20)\n",
    "# temperature\n",
    "tau = tf.Variable(5.0,name=\"temperature\")\n",
    "# sample and reshape back (shape=(batch_size,N,K))\n",
    "# set hard=True for ST Gumbel-Softmax\n",
    "y = tf.reshape(gumbel_softmax(logits_y,tau,hard=True),[-1,N,K])\n",
    "# generative model p(x|y), i.e. the decoder (shape=(batch_size,200))\n",
    "net = slim.stack(slim.flatten(y),slim.fully_connected,[256,512])\n",
    "logits_x = slim.fully_connected(net,784,activation_fn=None)\n",
    "# (shape=(batch_size,784))\n",
    "p_x = Bernoulli(logits=logits_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and train ops\n",
    "kl_tmp = tf.reshape(q_y*(log_q_y-tf.log(1.0/K)),[-1,N,K])\n",
    "KL = tf.reduce_sum(kl_tmp,[1,2])\n",
    "elbo=tf.reduce_sum(p_x.log_prob(x),1) - KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "loss=tf.reduce_mean(-elbo)\n",
    "lr=tf.constant(0.001)\n",
    "train_op=tf.train.AdamOptimizer(learning_rate=lr).minimize(loss,var_list=slim.get_model_variables())\n",
    "init_op=tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "data = input_data.read_data_sets('/tmp/', one_hot=True).train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=100\n",
    "NUM_ITERS=50000\n",
    "tau0=1.0 # initial temperature\n",
    "np_temp=tau0\n",
    "np_lr=0.001\n",
    "ANNEAL_RATE=0.00003\n",
    "MIN_TEMP=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, ELBO: -546.220\n",
      "Step 5001, ELBO: -125.669\n",
      "Step 10001, ELBO: -118.025\n",
      "Step 15001, ELBO: -116.573\n"
     ]
    }
   ],
   "source": [
    "dat=[]\n",
    "sess=tf.InteractiveSession()\n",
    "sess.run(init_op)\n",
    "for i in range(1,NUM_ITERS):\n",
    "  np_x,np_y=data.next_batch(BATCH_SIZE)\n",
    "  _,np_loss=sess.run([train_op,loss],{\n",
    "      x:np_x,\n",
    "      tau:np_temp,\n",
    "      lr:np_lr\n",
    "    })\n",
    "  if i % 100 == 1:\n",
    "    dat.append([i,np_temp,np_loss])\n",
    "  if i % 1000 == 1:\n",
    "    np_temp=np.maximum(tau0*np.exp(-ANNEAL_RATE*i),MIN_TEMP)\n",
    "    np_lr*=0.9\n",
    "  if i % 5000 == 1:\n",
    "    print('Step %d, ELBO: %0.3f' % (i,-np_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save to animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_x1,_=data.next_batch(100)\n",
    "np_x2,np_y1 = sess.run([p_x.mean(),y],{x:np_x1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_anim(data,figsize,filename):\n",
    "  fig=plt.figure(figsize=(figsize[1]/10.0,figsize[0]/10.0))\n",
    "  im = plt.imshow(data[0].reshape(figsize),cmap=plt.cm.gray,interpolation='none')\n",
    "  plt.gca().set_axis_off()\n",
    "  #fig.tight_layout()\n",
    "  fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=None, hspace=None)\n",
    "  def updatefig(t):\n",
    "    im.set_array(data[t].reshape(figsize))\n",
    "    return im,\n",
    "  anim=animation.FuncAnimation(fig, updatefig, frames=100, interval=50, blit=True, repeat=True)\n",
    "  Writer = animation.writers['imagemagick']\n",
    "  writer = Writer(fps=1, metadata=dict(artist='Me'), bitrate=1800)\n",
    "  anim.save(filename, writer=writer)\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_anim(np_x1,(28,28),'x0.gif')\n",
    "# save_anim(np_y1,(N,K),'y.gif')\n",
    "# save_anim(np_x2,(28,28),'x1.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat=np.array(dat).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,axarr=plt.subplots(1,2)\n",
    "axarr[0].plot(dat[0],dat[1])\n",
    "axarr[0].set_ylabel('Temperature')\n",
    "axarr[1].plot(dat[0],dat[2])\n",
    "axarr[1].set_ylabel('-ELBO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Unconditional Generation\n",
    "\n",
    "This consists of sampling from the prior $p_\\theta(y)$ and passing it through the generative model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=100*N\n",
    "np_y = np.zeros((M,K))\n",
    "np_y[range(M),np.random.choice(K,M)] = 1\n",
    "np_y = np.reshape(np_y,[100,N,K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_p=p_x.mean()\n",
    "np_x= sess.run(x_p,{y:np_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_y = np_y.reshape((10,10,N,K))\n",
    "np_y = np.concatenate(np.split(np_y,10,axis=0),axis=3)\n",
    "np_y = np.concatenate(np.split(np_y,10,axis=1),axis=2)\n",
    "y_img = np.squeeze(np_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_x = np_x.reshape((10,10,28,28))\n",
    "# split into 10 (1,10,28,28) images, concat along columns -> 1,10,28,280\n",
    "np_x = np.concatenate(np.split(np_x,10,axis=0),axis=3)\n",
    "# split into 10 (1,1,28,280) images, concat along rows -> 1,1,280,280\n",
    "np_x = np.concatenate(np.split(np_x,10,axis=1),axis=2)\n",
    "x_img = np.squeeze(np_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,axarr=plt.subplots(1,2,figsize=(15,15))\n",
    "# samples\n",
    "axarr[0].matshow(y_img,cmap=plt.cm.gray)\n",
    "axarr[0].set_title('Z Samples')\n",
    "# reconstruction\n",
    "axarr[1].imshow(x_img,cmap=plt.cm.gray,interpolation='none')\n",
    "axarr[1].set_title('Generated Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.tight_layout()\n",
    "f.savefig('/Users/ericjang/Desktop/gumbel_softmax/code.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
